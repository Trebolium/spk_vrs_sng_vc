<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zero-shot Singing Technique Conversion</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Quantifying Dissimilarity Between Speech and Singing Domains, and How This Affects Voice Conversion Tasks</h1>
    <p id="p1">This page presents SVC audio clips from our research on comparisons between singing and speech domain data. In addition to the methods described in our paper, we also use voice conversion tasks to evaluate how well cross-domain tasks apply between speech and singing. </p>

    <!-- <p id="p1">This page presents the results and stimuli used in our research on singing voice conversion, as detailed in our SMC 2023 submitted paper, Zero-shot Singing Technique Conversion.
        Directly below are the results of our listening study. </p> -->

    <!-- <img class="img-stats" src="barchart-natSimCos.png" alt="Histograms of naturalness and specificity scores of generated audio"> -->
    <!-- <figcaption>Upper barchart shows naturalness MOS, middle barchart shows similarity MOS, and bottom barchart shows cosine similarity. Colours highlight the conditional categories: models, source genders, target genders, and source-target gender pairs   . </figcaption> -->

    <p>To illustrate the upperbound limit for quality of our generated audio, the table below presents examples where audio recordings have been converted to mel spectrograms and resynthesized into audio using the pretrained Wavenet vocoder.
        This demonstrates the artefacts and deterioration due to resynthesis alone, and therefore provides an indication of the upperbound audio quality that other audio clips can be compared against for reference:</p>

    <div class="grid-container1">
        <div class="grid-item head">Original</div>
        <div class="grid-item head">Resynthesized</div>      
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M819000103_timestep7792_F1288160835_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M609235072_timestep1632_M148187151_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F914688212_timestep3152_M618517515_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F1209787220_timestep7520_F1118781094_target.wav"></audio></div>
    </div>
    
    <h3>Spoken Voice Conversion with/without latent regressor loss</h3>

    <p> The audio files presented in the table below have been generated by an AutoVC network that used the bottleneck latent regressor loss,
        and was trained for 100,000 training steps on a quarter of the VCTK dataset.
        The input data was in a mel-spectrogram format.
        It was conditioned on VIEs from an encoder that was pretrained on the LibriSpeech and VoxCeleb1 datasets.
        The table shown below is arranged to present a comparison between source vocalist, target vocalist and converted voice singing clips, generated by this model:
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p225_p226.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p226_p227.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p227_p228.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p228_p225.wav"></audio></div>    

    </div>


    <p> For comparison, the audio files presented in this next table below come from an AutoVC model that was trained under the same conditions as the aforementioned model,
        but instead only used the reconstruction loss in its objective function. It can be heard from these examples, that the output audio is significantly less distorted or ambiguous in timbre.
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p225_p226.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p226_p227.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p227_p228.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p228_p225.wav"></audio></div>    

    </div>

    <h3> Singing Voice Conversion </h3>

    <p> The audio files presented in the table below have been generated by an AutoVC network that took WORLD spectral envelope features as input, using only reconstruction loss. The VIE encoder that was trained on the entire DAMP datasets.
        This AutoVC network was trained for 100,000 training steps on a quarter of the DAMP dataset. Here we observe conversions perceptually specific to microphone placement, loudness and room frequency reponse - but not vocal timbre.
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/426780220_1027314259.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/1027314259_1050554650.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/1050554650_1615650453.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/1615650453_426780220.wav"></audio></div>

    </div> 

    <p> For comparison, the audio files presented in this next table below have been generated by a model trained under the same conditions as the SVC model mentioned above, except for itst input features which were mel spectrograms.
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/426780220_1027314259.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/1027314259_1050554650.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/1050554650_1615650453.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/1615650453_426780220.wav"></audio></div>

    </div>

    <h3> Models trained for 500k steps </h3>

    <p> The audio files presented in the remaining two tables below have been generated by AutoVC networks that used both reconstruction and bottleneck latent regressor loss componets in their objective function.
        They were trained for 500,000 steps on a quarter of the DAMP dataset
    </p>
        
    <p> The table below presents converted audio synthesized by the model just mentioned, when trained using a VIE pretrained on the LibriSpeech and VoxCeleb1 datasets.
    </p>
    
    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F291470337_timestep1730_M475351623_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F291470337_timestep1730_M475351623.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F771524047_timestep3566_F236486784_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F771524047_timestep3566_F236486784.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M1654991314_timestep4850_M1473212998_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M1654991314_timestep4850_M1473212998.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M1473212998_timestep1822_F914688212_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M1473212998_timestep1822_F914688212.wav"></audio></div>    

    </div>

    <p> The table below presents converted audio synthesized the model just mentioned, when trained using a VIE pretrained on the DAMP dataset.
    </p>
    
    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F197252304_timestep5464_M153391661_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F197252304_timestep5464_M153391661.wav"></audio></div>

        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F265860251_timestep10056_F1705464848_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F265860251_timestep10056_F1705464848.wav"></audio></div>

        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M473926181_timestep827_M475351623_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M473926181_timestep827_M475351623.wav"></audio></div>

        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M1224586431_timestep7530_F702021966_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M1224586431_timestep7530_F702021966.wav"></audio></div>    

    </div>

</body>
</html>
